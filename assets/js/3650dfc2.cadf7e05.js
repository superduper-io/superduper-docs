"use strict";(self.webpackChunknewdocs=self.webpackChunknewdocs||[]).push([[410],{2869:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>i,default:()=>m,frontMatter:()=>s,metadata:()=>o,toc:()=>d});var r=t(4848),a=t(8453);const s={},i="PDF RAG",o={id:"templates/pdf_rag",title:"PDF RAG",description:"This is a PDF-based RAG application. While answering questions, it accesses relevant information from the PDF and displays the corresponding paragraphs in the form of images.",source:"@site/docs/templates/pdf_rag.md",sourceDirName:"templates",slug:"/templates/pdf_rag",permalink:"/docs/templates/pdf_rag",draft:!1,unlisted:!1,editUrl:"https://github.com/superduper-io/superduper/edit/main/docs/docs/templates/pdf_rag.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Multimodal vector search - Video",permalink:"/docs/templates/multimodal_video_search"},next:{title:"Retrieval augmented generation",permalink:"/docs/templates/rag"}},l={},d=[{value:"Create a table to store PDFs.",id:"create-a-table-to-store-pdfs",level:2},{value:"Split the PDF file into images for later result display",id:"split-the-pdf-file-into-images-for-later-result-display",level:2},{value:"Build a chunks model and return chunk results with coordinate information.",id:"build-a-chunks-model-and-return-chunk-results-with-coordinate-information",level:2},{value:"Build a vector index for vector search",id:"build-a-vector-index-for-vector-search",level:2},{value:"Create a plugin",id:"create-a-plugin",level:2},{value:"Create a RAG model",id:"create-a-rag-model",level:2},{value:"Create template",id:"create-template",level:2}];function p(e){const n={code:"code",h1:"h1",h2:"h2",p:"p",pre:"pre",...(0,a.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.h1,{id:"pdf-rag",children:"PDF RAG"}),"\n",(0,r.jsx)(n.p,{children:"This is a PDF-based RAG application. While answering questions, it accesses relevant information from the PDF and displays the corresponding paragraphs in the form of images."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"from superduper import superduper\n"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'db = superduper("mongodb://localhost:27017/pdf_rag")\ndb.drop(True, True)\n'})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"!curl -O https://superduperdb-public-demo.s3.amazonaws.com/pdfs.zip && unzip -o pdfs.zip\n"})}),"\n",(0,r.jsx)(n.h2,{id:"create-a-table-to-store-pdfs",children:"Create a table to store PDFs."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import os\nfrom superduper import Schema, Table\nfrom superduper.components.datatype import file_lazy\n\n\n\nschema = Schema(identifier="myschema", fields={"url": "str", "file": file_lazy})\ntable = Table(identifier="pdfs", schema=schema)\ndb.apply(table, force=True)\n\npdf_folder = "pdfs"\npdf_names = [pdf for pdf in os.listdir(pdf_folder) if pdf.endswith(".pdf")]\npdf_paths = [os.path.join(pdf_folder, pdf) for pdf in pdf_names]\n\ndata = [{"url": pdf_path, "file": pdf_path} for pdf_path in pdf_paths]\n\ndb["pdfs"].insert(data).execute()\n'})}),"\n",(0,r.jsx)(n.h2,{id:"split-the-pdf-file-into-images-for-later-result-display",children:"Split the PDF file into images for later result display"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'def split_image(pdf_path):\n    logging.info(f"Splitting images from {pdf_path}")\n    from pdf2image import convert_from_path\n\n    image_folders = "data/pdf-images"\n    pdf_name = os.path.basename(pdf_path)\n    images = convert_from_path(pdf_path)\n    logging.info(f"Number of images: {len(images)}")\n\n    image_folder = os.path.join(image_folders, pdf_name)\n    if not os.path.exists(image_folder):\n        os.makedirs(image_folder)\n\n    data = []\n    for i, image in enumerate(images):\n        path = os.path.join(image_folder, f"{i}.jpg")\n        image.save(os.path.join(path))\n        data.append(path)\n    return data\n\nfrom superduper import ObjectModel\n\nmodel_split_image = ObjectModel(\n    identifier="split_image",\n    object=split_image,\n    datatype=file_lazy,\n)\n\nlistener_split_image = model_split_image.to_listener(\n    key="file",\n    select=db["pdfs"].find(),\n    flatten=True,\n)\ndb.apply(listener_split_image, force=True)\n'})}),"\n",(0,r.jsx)(n.h2,{id:"build-a-chunks-model-and-return-chunk-results-with-coordinate-information",children:"Build a chunks model and return chunk results with coordinate information."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'def remove_sidebars(elements):\n    import re\n    from collections import defaultdict\n\n    from unstructured.documents.elements import ElementType\n\n    if not elements:\n        return elements\n    points_groups = defaultdict(list)\n    min_x = 99999999\n    max_x = 0\n    e2index = {e.id: i for i, e in enumerate(elements)}\n    for e in elements:\n        x_l = int(e.metadata.coordinates.points[0][0])\n        x_r = int(e.metadata.coordinates.points[2][0])\n        points_groups[(x_l, x_r)].append(e)\n        min_x = min(min_x, x_l)\n        max_x = max(max_x, x_r)\n    sidebars_elements = set()\n    for (x_l, x_r), es in points_groups.items():\n        first_id = e2index[es[0].id]\n        last_id = e2index[es[-1].id]\n        on_left = first_id == 0 and x_l == min_x\n        on_right = (last_id == len(elements) - 2) and x_r == max_x\n        loc_match = [on_left, on_right]\n        total_text = "".join(map(str, es))\n        condiction = [\n            any(loc_match),\n            len(es) >= 3,\n            re.findall("^[A-Z\\s\\d,]+$", total_text),\n        ]\n        if not all(condiction):\n            continue\n        sidebars_elements.update(map(lambda x: x.id, es))\n        if on_left:\n            check_page_num_e = elements[last_id + 1]\n        else:\n            check_page_num_e = elements[-1]\n        if (\n            check_page_num_e.category == ElementType.UNCATEGORIZED_TEXT\n            and check_page_num_e.text.strip().isalnum()\n        ):\n            sidebars_elements.add(check_page_num_e.id)\n\n    elements = [e for e in elements if e.id not in sidebars_elements]\n    return elements\n\n\ndef remove_annotation(elements):\n    from collections import Counter\n\n    from unstructured.documents.elements import ElementType\n\n    page_num = max(e.metadata.page_number for e in elements)\n    un_texts_counter = Counter(\n        [e.text for e in elements if e.category == ElementType.UNCATEGORIZED_TEXT]\n    )\n    rm_text = set()\n    for text, count in un_texts_counter.items():\n        if count / page_num >= 0.5:\n            rm_text.add(text)\n    elements = [e for e in elements if e.text not in rm_text]\n    return elements\n\n\ndef create_chunk_and_metadatas(page_elements, stride=3, window=10):\n    page_elements = remove_sidebars(page_elements)\n    for index, page_element in enumerate(page_elements):\n        page_element.metadata.num = index\n    datas = []\n    for i in range(0, len(page_elements), stride):\n        windown_elements = page_elements[i : i + window]\n        chunk = "\\n".join([e.text for e in windown_elements])\n        source_elements = [e.to_dict() for e in windown_elements]\n        datas.append(\n            {\n                "txt": chunk,\n                "source_elements": source_elements,\n            }\n        )\n    return datas\n\n\ndef get_chunks(pdf):\n    from collections import defaultdict\n\n    from unstructured.documents.coordinates import RelativeCoordinateSystem\n    from unstructured.partition.pdf import partition_pdf\n\n    elements = partition_pdf(pdf)\n    elements = remove_annotation(elements)\n\n    pages_elements = defaultdict(list)\n    for element in elements:\n        element.convert_coordinates_to_new_system(\n            RelativeCoordinateSystem(), in_place=True\n        )\n        pages_elements[element.metadata.page_number].append(element)\n\n    all_chunks_and_links = sum(\n        [\n            create_chunk_and_metadatas(page_elements)\n            for _, page_elements in pages_elements.items()\n        ],\n        [],\n    )\n    return all_chunks_and_links\n\n'})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'model_chunk = ObjectModel(\n    identifier="chunk",\n    object=get_chunks,\n)\n\nlistener_chunk = model_chunk.to_listener(\n    key="file",\n    select=db["pdfs"].select(),\n    flatten=True,\n)\ndb.apply(listener_chunk, force=True)\n'})}),"\n",(0,r.jsx)(n.h2,{id:"build-a-vector-index-for-vector-search",children:"Build a vector index for vector search"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from superduper_openai.model import OpenAIEmbedding\nfrom superduper import VectorIndex\n\n\nmodel_embedding = OpenAIEmbedding(\n    identifier="embedding",\n    model="text-embedding-ada-002",\n)\n\nlistener_embedding = model_embedding.to_listener(\n    key="_outputs__chunk.txt",\n    select=db["_outputs__chunk"].select(),\n)\n\nvector_index = VectorIndex(\n    identifier="vector-index",\n    indexing_listener=listener_embedding,\n)\n\ndb.apply(vector_index, force=True)\n\n'})}),"\n",(0,r.jsx)(n.h2,{id:"create-a-plugin",children:"Create a plugin"}),"\n",(0,r.jsx)(n.p,{children:"When applying the processor, saves the plugin in the database, thereby saving the related dependencies as well."}),"\n",(0,r.jsx)(n.p,{children:"The processor will integrate the returned chunks information with the images, and return a visualized image.\u200b"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from superduper import Plugin\nfrom utils import Processer\nprocessor = Processer(identifier="processor", db=db, plugins=[Plugin(path="./utils.py")])\n'})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python"})}),"\n",(0,r.jsx)(n.h2,{id:"create-a-rag-model",children:"Create a RAG model"}),"\n",(0,r.jsx)(n.p,{children:"Create a RAG model to perform retrieval-augmented generation (RAG) and return the results."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from superduper import Model, logging\n\n\nclass Rag(Model):\n\n    llm_model: Model\n    prompt_template: str\n    processor: None | Model = None\n\n    def __post_init__(self, *args, **kwargs):\n        assert "{context}" in self.prompt_template, \'The prompt_template must include "{context}"\'\n        assert "{query}" in self.prompt_template, \'The prompt_template must include "{query}"\'\n        super().__post_init__(*args, **kwargs)\n    \n    def predict(self, query, top_k=5, format_result=False):\n        vector_search_out = self.vector_search(query, top_k=top_k)\n        context = "\\n\\n---\\n\\n".join([x["_outputs__chunk.txt"] for x in vector_search_out])\n        \n        prompt = self.prompt_template.format(context=context, query=query)\n        output = self.llm_model.predict(prompt)\n        result = {\n            "answer": output,\n            "docs": vector_search_out,\n        }\n        if format_result and self.processor:\n            result["images"] = list(self.processor.predict(vector_search_out, match_text=output, merge=True))\n        return result\n\n    def vector_search(self, query, top_k=5, format_result=False):\n        logging.info(f"Vector search query: {query}")\n        select = self.db["_outputs__chunk"].like(\n            {"_outputs__chunk.txt":query},\n            vector_index="vector-index", \n            n=top_k,\n        ).select()\n        out = select.execute()\n        if out:\n            out = sorted(out, key=lambda x: x["score"], reverse=True)\n        return out\n'})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from superduper_openai.model import OpenAIChatCompletion\n\nllm = OpenAIChatCompletion(identifier="llm", model="gpt-3.5-turbo")\n\nprompt_template = (\n    "The following is a document and question about the volvo user manual\\n"\n    "Only provide a very concise answer\\n"\n    "Context:\\n\\n"\n    "{context}\\n\\n"\n    "Here\'s the question:{query}\\n"\n    "answer:"\n)\n\nrag = Rag(identifier="rag", llm_model=llm, prompt_template=prompt_template, db=db, processor=processor)\ndb.apply(rag, force=True)\n'})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'result = rag.predict("How to perform Query Optimization?", format_result=True)\n'})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from IPython.display import Image, Markdown, display\n\ndisplay(Markdown(result["answer"]))\n\nfor message, img in result["images"]:\n    display(Markdown(message))\n    display(img)\n'})}),"\n",(0,r.jsx)(n.h2,{id:"create-template",children:"Create template"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from superduper import Application, Template\n\napp = Application.build_from_db(db=db, identifier="pdf-rag")\n'})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"from superduper import Template\n\ntemplate = Template('pdf-rag', template=app, substitutions={prompt_template: 'prompt_template'})\n"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"template.template_variables\n"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'template.export(".")\n'})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python"})})]})}function m(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(p,{...e})}):p(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>i,x:()=>o});var r=t(6540);const a={},s=r.createContext(a);function i(e){const n=r.useContext(s);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:i(e.components),r.createElement(s.Provider,{value:n},e.children)}}}]);