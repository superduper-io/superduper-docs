"use strict";(self.webpackChunknewdocs=self.webpackChunknewdocs||[]).push([[4937],{5264:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>i,contentTitle:()=>l,default:()=>c,frontMatter:()=>a,metadata:()=>o,toc:()=>d});var r=t(4848),s=t(8453);const a={},l="Retrieval augmented generation",o={id:"templates/rag",title:"Retrieval augmented generation",description:"Connect to superduper",source:"@site/docs/templates/rag.md",sourceDirName:"templates",slug:"/templates/rag",permalink:"/docs/templates/rag",draft:!1,unlisted:!1,editUrl:"https://github.com/superduper-io/superduper/edit/main/docs/docs/templates/rag.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"PDF RAG",permalink:"/docs/templates/pdf_rag"},next:{title:"Simple retrieval augmented generation with OpenAI",permalink:"/docs/templates/simple_rag"}},i={},d=[{value:"Connect to superduper",id:"connect-to-superduper",level:2},{value:"Insert simple data",id:"insert-simple-data",level:2},{value:"Apply a chunker for search",id:"apply-a-chunker-for-search",level:2},{value:"Select outputs of upstream listener",id:"select-outputs-of-upstream-listener",level:2},{value:"Build text embedding model",id:"build-text-embedding-model",level:2},{value:"Create vector-index",id:"create-vector-index",level:2},{value:"Build LLM",id:"build-llm",level:2},{value:"Answer question with LLM",id:"answer-question-with-llm",level:2},{value:"Create template",id:"create-template",level:2}];function p(e){const n={admonition:"admonition",code:"code",em:"em",h1:"h1",h2:"h2",p:"p",pre:"pre",strong:"strong",...(0,s.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.h1,{id:"retrieval-augmented-generation",children:"Retrieval augmented generation"}),"\n",(0,r.jsx)(n.h2,{id:"connect-to-superduper",children:"Connect to superduper"}),"\n",(0,r.jsx)(n.admonition,{type:"note",children:(0,r.jsx)(n.p,{children:'Note that this is only relevant if you are running superduper in development mode.\nOtherwise refer to "Configuring your production system".'})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"APPLY = False\nCOLLECTION_NAME = '<var:table_name>' if not APPLY else 'sample_rag'\nID_FIELD = '<var:id_field>' if not APPLY else 'id'\n"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"from superduper import superduper, CFG\n\nCFG.bytes_encoding = 'str'\nCFG.json_native = False\n\ndb = superduper('mongomock://test_db')\n"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"import json\nimport requests\nimport io\n\ndef getter():\n    response = requests.get('https://superduperdb-public-demo.s3.amazonaws.com/text.json')\n    data = json.loads(response.content.decode('utf-8'))\n    return [{'x': r} for r in data]\n"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"if APPLY:\n    data = getter()\n"})}),"\n",(0,r.jsx)(n.h2,{id:"insert-simple-data",children:"Insert simple data"}),"\n",(0,r.jsx)(n.p,{children:"After turning on auto_schema, we can directly insert data, and superduper will automatically analyze the data type, and match the construction of the table and datatype."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"if APPLY:\n    from superduper import Document\n    ids = db.execute(db[COLLECTION_NAME].insert([Document(r) for r in data]))\n"})}),"\n",(0,r.jsx)(n.h2,{id:"apply-a-chunker-for-search",children:"Apply a chunker for search"}),"\n",(0,r.jsx)(n.admonition,{type:"note",children:(0,r.jsxs)(n.p,{children:["Note that applying a chunker is ",(0,r.jsx)(n.em,{children:(0,r.jsx)(n.strong,{children:"not"})})," mandatory for search.\nIf your data is already chunked (e.g. short text snippets or audio) or if you\nare searching through something like images, which can't be chunked, then this\nwon't be necessary."]})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"from superduper import Model\n\n\nclass Chunker(Model):\n    chunk_size: int = 200\n    signature: str = 'singleton'\n\n    def predict(self, text):\n        text = text.split()\n        chunks = [' '.join(text[i:i + self.chunk_size]) for i in range(0, len(text), self.chunk_size)]\n        return chunks\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Now we apply this chunker to the data by wrapping the chunker in ",(0,r.jsx)(n.code,{children:"Listener"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"from superduper import Listener\n\n\nupstream_listener = Listener(\n    model=Chunker(identifier='chunker'),\n    select=db[COLLECTION_NAME].select(ID_FIELD, 'x'),\n    key='x',\n    identifier='chunker',\n    flatten=True,\n)\n"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"if APPLY:\n    db.apply(upstream_listener, force=True)\n"})}),"\n",(0,r.jsx)(n.h2,{id:"select-outputs-of-upstream-listener",children:"Select outputs of upstream listener"}),"\n",(0,r.jsx)(n.admonition,{type:"note",children:(0,r.jsx)(n.p,{children:"This is useful if you have performed a first step, such as pre-computing\nfeatures, or chunking your data. You can use this query to\noperate on those outputs."})}),"\n",(0,r.jsx)(n.h2,{id:"build-text-embedding-model",children:"Build text embedding model"}),"\n",(0,r.jsx)(n.p,{children:"OpenAI:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"import os\nfrom superduper.components.vector_index import sqlvector\n\nfrom superduper_openai import OpenAIEmbedding\n\nopenai_embedding = OpenAIEmbedding(identifier='text-embedding-ada-002' , datatype=sqlvector(shape=(1536,)))\n"})}),"\n",(0,r.jsx)(n.p,{children:"Sentence-transformers"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'import sentence_transformers\nfrom superduper_sentence_transformers import SentenceTransformer\n\nsentence_transformers_embedding = SentenceTransformer(\n    identifier="sentence-transformers-embedding",\n    model="BAAI/bge-small-en",\n    datatype=sqlvector(shape=(1024,)),\n    postprocess=lambda x: x.tolist(),\n    predict_kwargs={"show_progress_bar": True},\n)\n'})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"from superduper.components.model import ModelRouter\nfrom superduper.components.vector_index import sqlvector\n\nembedding_model = ModelRouter(\n    'embedding',\n    models={'openai': openai_embedding, 'sentence_transformers': sentence_transformers_embedding},\n    model='<var:embedding_model>' if not APPLY else 'openai',\n    example='this is a test',\n)\n"})}),"\n",(0,r.jsx)(n.h2,{id:"create-vector-index",children:"Create vector-index"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"from superduper import VectorIndex, Listener\n\nvector_index_name = 'vectorindex'\n\nvector_index = VectorIndex(\n    vector_index_name,\n    indexing_listener=Listener(\n        key=upstream_listener.outputs,\n        select=db[upstream_listener.outputs].select(ID_FIELD, '_source', upstream_listener.outputs),\n        model=embedding_model,\n        identifier='embeddinglistener',\n        upstream=[upstream_listener],\n    )\n)\n"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"if APPLY:\n    db.apply(vector_index, force=True)\n"})}),"\n",(0,r.jsx)(n.h2,{id:"build-llm",children:"Build LLM"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"from superduper_openai import OpenAIChatCompletion\n\nllm_openai = OpenAIChatCompletion(identifier='llm-openai', model='gpt-3.5-turbo')\n"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"from superduper_anthropic import AnthropicCompletions\n\npredict_kwargs = {\n    \"max_tokens\": 1024,\n    \"temperature\": 0.8,\n}\n\nllm_anthropic = AnthropicCompletions(identifier='llm-vllm', model='claude-2.1', predict_kwargs=predict_kwargs)\n"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from superduper_vllm import VllmCompletion\n\npredict_kwargs = {\n    "max_tokens": 1024,\n    "temperature": 0.8,\n}\n\nllm_vllm = VllmCompletion(\n    identifier="llm-vllm",\n    vllm_params={\n        \'model\': \'TheBloke/Mistral-7B-Instruct-v0.2-AWQ\',\n        "gpu_memory_utilization": 0.7,\n        "max_model_len": 1024,\n        "quantization": "awq",\n    },\n    predict_kwargs=predict_kwargs,\n)\n'})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# # !huggingface-cli download TheBloke/Mistral-7B-Instruct-v0.2-GGUF mistral-7b-instruct-v0.2.Q4_K_M.gguf --local-dir . --local-dir-use-symlinks False\n# from superduper_llamacpp.model import LlamaCpp\n\n# llm_llamacpp = LlamaCpp(identifier="llm-llamacpp", model_name_or_path="mistral-7b-instruct-v0.2.Q4_K_M.gguf")\n'})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"llm = ModelRouter(\n    'llm',\n    models={\n        'openai': llm_openai,\n        'anthropic': llm_anthropic,\n        'vllm': llm_vllm,\n        # 'llamacpp': llm_llamacpp,\n    },\n    model='<var:llm_model>' if not APPLY else 'openai',\n)\n"})}),"\n",(0,r.jsx)(n.h2,{id:"answer-question-with-llm",children:"Answer question with LLM"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'from superduper import model\nfrom superduper.components.model import RAGModel\n\nprompt_template = (\n    "Use the following context snippets, these snippets are not ordered!, Answer the question based on this context.\\n"\n    "{context}\\n\\n"\n    "Here\'s the question: {query}"\n)\n\nrag = RAGModel(\n    \'rag-model\',\n    select=db[upstream_listener.outputs].select().like({upstream_listener.outputs: \'<var:query>\'}, vector_index=vector_index_name, n=5),\n    prompt_template=prompt_template,\n    key=upstream_listener.outputs,\n    llm=llm,\n)\n'})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"if APPLY:\n    db.apply(rag, force=True)\n"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"if APPLY:\n    print(rag.predict('Tell me about vector-search'))\n"})}),"\n",(0,r.jsx)(n.p,{children:"By applying the RAG model to the database, it will subsequently be accessible for use in other services."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"from superduper import Application\n\napp = Application(\n    'rag-app',\n    components=[\n        upstream_listener,\n        vector_index,\n        rag,\n    ]\n)\n"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"if APPLY:\n    db.apply(app, force=True)\n"})}),"\n",(0,r.jsx)(n.p,{children:"You can now load the model elsewhere and make predictions using the following command."}),"\n",(0,r.jsx)(n.h2,{id:"create-template",children:"Create template"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"from superduper import Template, Table, Schema\nfrom superduper.components.dataset import RemoteData\n\n\ntemplate = Template(\n    'rag',\n    template=app,\n    default_table=Table(\n        'sample_rag',\n        schema=Schema(\n            'sample_rag/schema',\n            fields={'txt': 'str'},\n        ),\n        data=RemoteData(\n            'superduper-docs',\n            getter=getter,\n        )\n    ),\n    substitutions={COLLECTION_NAME: 'table_name'},\n    template_variables=['llm_model', 'embedding_model', 'table_name', 'id_field'],\n    types={\n        'id_field': {\n            'type': 'str',\n            'default': '_id',\n        },\n        'llm_model': {\n            'type': 'str',\n            'choices': ['openai', 'anthropic', 'vllm', 'llamacpp'],\n            'default': 'openai',\n        },\n        'embedding_model': {\n            'type': 'str',\n            'choices': ['openai', 'sentence_transformers'],\n            'default': 'openai',\n        },\n        'table_name': {\n            'type': 'str',\n            'default': 'sample_rag'\n        },\n    }\n)\n"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"template.export('.')\n"})})]})}function c(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(p,{...e})}):p(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>l,x:()=>o});var r=t(6540);const s={},a=r.createContext(s);function l(e){const n=r.useContext(a);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:l(e.components),r.createElement(a.Provider,{value:n},e.children)}}}]);